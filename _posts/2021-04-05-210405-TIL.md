---
layout: post
title:  "TIL 210405"
description: "선형 회귀 복습"
author: SeungRok OH
categories: [TIL]
---

# 2021.04.05 TIL

- 선형회귀 복습.



# 선형회귀 분석

### 기본



numpy , sckit-learn, statsmodel 3가지 모두 가능하고 주로 sckit-learn 또는 statsmodel을 통해 분석을 실시한다.



- sckit-learn의 경우 먼저 클래스 객체를 생성하고 fitting을 진행한다.

  model = LinearRegression(fit_intercept=True) (상수항 추가 디폴트가 True라 굳이 기입하지 않아도 된다.)

  model = model.fit(X, y)



- statsmodel의 경우 또 두가지 방법으로 회귀분석을 진행할 수 있는데

  1. model = sm.OLS.from_fromula(formula, data=df) 
  2. model = OLS(dfy, dfx) 

  2에선 1과 다르게 타겟변수와 독립변수를 나누어 인수로 넣어주어야 한다. dfx의 경우 add_constant 명령을 통해 상수항을 추가시켜주어야 한다.



result = model.fit()

y_new = result.predict(X_test)



1번의 경우 model = sm.OLS.from_formula("y ~ x", data=df) / result = model.fit()

​			   	 model = sm.OLS.from_formula("MEDV ~" + "+".join(boston.feature_names), data=df)

join써서 문자열 넣기



2번의 경우 dfy = df["y"] / dfX = sm.add_constant(df[['x']]) / model = sm.OLS(dfy, dfX) / result = model.fit()

print(result.summary()) 분석보고서가 나옴.

해당 data에 대한 분석값을 알고 싶을 경우 result.predict({'x' : [-2, -1, 0, 1, 2] }) 와 같이 dict 형식으로 입력한다.



 (성질) 잔차의 합은 0 ,  x의 평균값을 넣으면 y의 평균값과 같은 값이 나온다.



조건수(condition number)가 크게 나오게 될 경우 오차가 많이 발생하며 1.변수들의 단위 차이가 크거나 2. 다중공선성이 발생했을때 조건수가 커지게 된다. 변수들의 단위는 스케일링을 통해 해결할 수 있으며 다중공선성의 경우 변수선택 또는 차원축소를 통해 해결해야 한다.



범주형 변수가 있을 경우 상수항은 포함하지 않는다.  대부분 범주형의 경우 축소랭크 방식으로 전처리를 한다.

하나의 기준값이 정해지고 기준값보다 얼마나 달라졌는지 비교가 용이해진다. (검정, 유의확률)

두개 이상의 범주형 변수가 있을 경우 무조건 축소랭크 방식을 사용.

범주형 과 실수형 독립변수가 서로 상호작용하여 타겟변수에 영향을 미친다면 곱하기 항을(실수형*범주형) 수동적으로 집어넣어야 한다. (기울기가 범주에 따라 달라지는 경우)



#### 부분회귀 

프리슈워-로벨 정리 

ex) x1(층수, 지역, 타입)  x2(면적)  y(집값)가 있을때 순수하게 x2(면적)가 y(집값)에 미치는 영향을 알고 싶을때는 x1으로 y를 예측하고 발생한 잔차(y!)를  x1으로 x2를 예측하여 발생한 잔차(x!)로 예측하면 알 수 있다.

x1으로 미처 알지 못하는 부분을 x2로 알아보자는 것이고, x2역시 x1에 영향을 받았기때문에 그 부분을 배제하고 남은 부분을 예측할때 사용하는 것이다.

sm.graphics.plot_partregress(종속변수 문자열, 독립변수 문자열(분석대상), 독립변수 문자열 리스트(나머지) , data=none, obs_labels=True(데이터라벨링 여부), ret_coords=False(잔차 데이터 반환 여부) )



ex) 보스턴 집값 예제에서 age변수와 medv(타겟)변수에 실제 상관관계

![1](https://user-images.githubusercontent.com/77723966/113553970-82fc3f80-9633-11eb-92be-bda400789270.PNG)

모든 변수에 대해서도 한번에 그릴 수 있다.

![2](https://user-images.githubusercontent.com/77723966/113553982-88f22080-9633-11eb-9bb4-6d3f4bd70080.PNG)

부분회귀 플롯과 마찬가지로 보여주는 CCPR플롯이란것도 존재하며 부분회귀플롯과 CCPR플롯을 같이 보여주는 명령이 있으며 실무에서 자주 사용된다. (plot_regress_exog)

![3](https://user-images.githubusercontent.com/77723966/113553992-8d1e3e00-9633-11eb-9f70-c9afd5d85214.PNG)

## 확률론적 선형 회귀모형

오차(계수에 관해)가 어느정도 인지 확률적으로 알고자 하는 것. // 정확한 W(가중치)값은 무엇인지



- 부트스트래핑

  데이터가 부족하기 때문에 오차값이 발생하고 정확한 w값을 알기 힘든것인데 부트스트래핑은 resampling(재표본화)이라는 방법을 통해 해결하고자 한다. 

  데이터를 일부 취사선택하여 많이 시도하여 나온 가중치 값을 비교한다. 이런 방법을 통해 나온 가중치 값이나 y절편 값은 '분포'(확률)로 나오게 되며 가장 높은 확률의 값을 알 수 있게 된다.

  시간이 오래 걸린다.

  

statsmodels의 summary에 나온 값들에서 부트스트래핑 없이 이 결과를 바로 알 수 가 있는데 이 경우 부트스트래핑이 아닌 '확률론적 선형 회귀모형'을 통해 가중치 추정값의 오차를 구한 것이다.

ste err는 우리가 구한 coef에 대한 표준오차이며,  우측에는 표준오차를 2배하여 신뢰구간을 표현하였다. 



- 확률론적 선형회귀 모형

  1. 선형 정규분포 가정

  2. 외생성 가정

  3. 조건부 독립 가정

  4. 등분산성 가정 

     

1. 선형 정규분포 가정 = 종속 변수 y가 x라는 독립변수의 선형조합으로 결정되는 기대값

![4](https://user-images.githubusercontent.com/77723966/113554003-91e2f200-9633-11eb-8e9a-95ef72fc4b69.PNG)


잡음은 잔차와는 또 다른 개념이다.   (잡음-disturbance ≠ 잔차-residual)

x에 따라 변하는 정규분포이기때문에 x,y 각각이 정규분포일 필요는 없다. 



2. 외생성 가정 = 잡음의 기대값은 독립변수 x의 크기에 상관없이 항상 0이라 가정한다.

![5](https://user-images.githubusercontent.com/77723966/113554010-960f0f80-9633-11eb-8dc7-a5469b57348b.PNG)

3. 조건부 독립 가정 = i번째 표본의 잡음과 j번째 표본의 잡음의 공분산 값이 x와 상관없이 항상 0이라고 가정한다. (잡음끼리는 상관관계가 없다)

![6](https://user-images.githubusercontent.com/77723966/113554015-99a29680-9633-11eb-9175-962c02096385.PNG)

4. 등분산성 가정 = i번째 표본의 잡음과 j번째 표본의 잡음의 분산 값이 표본과 상관없이 항상 같다고 가정한다.

